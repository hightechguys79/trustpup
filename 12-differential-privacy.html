<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>üê∂ Differential Privacy (DP)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body{font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;line-height:1.65;margin:0;background:#fafafa;color:#222}
    main{max-width:860px;margin:40px auto;padding:0 20px;background:#fff;border-radius:12px;box-shadow:0 10px 30px rgba(0,0,0,.05)}
    header{padding:28px 28px 0}
    h1{margin:0 0 8px}
    section{padding:18px 28px}
    h2{margin:0 0 8px;font-size:1.1rem;color:#0b5fff;text-transform:uppercase;letter-spacing:.04em}
    ul{padding-left:18px}
    .tag{display:inline-block;background:#eef4ff;color:#0b5fff;border-radius:999px;padding:2px 10px;font-size:.8rem;margin-left:.4rem}
    .refs a{color:#0b5fff;text-decoration:none}
    .refs li{margin:.35rem 0}
    code{background:#f3f6ff;padding:.15rem .35rem;border-radius:6px}
  </style>
</head>
<body>
<main>
  <header>
    <h1>üê∂ Differential Privacy (DP) <span class="tag">Aggregate Insights, Individual Privacy</span></h1>
    <p>Get the trend without outing the friend: protect people by adding carefully tuned noise.</p>
  </header>

  <section>
    <h2>What</h2>
    <p><strong>Differential Privacy</strong> adds mathematical noise to results so you can learn about groups while hiding any one person‚Äôs contribution. It sets a privacy budget (<code>Œµ</code>, ‚Äúepsilon‚Äù) that bounds how much info can leak about an individual from any output.</p>
  </section>

  <section>
    <h2>Why It Matters</h2>
    <p>It thwarts re-identification attacks on published statistics and model outputs, letting you share insights responsibly (and often legally) without exposing users.</p>
  </section>

  <section>
    <h2>Example</h2>
    <ul>
      <li><strong>Apple (telemetry):</strong> Uses local DP to collect trends like emoji usage without learning any one person‚Äôs exact behavior.</li>
      <li><strong>Retail analytics:</strong> Add noise to basket analysis so ‚Äútop combos‚Äù are shareable without revealing a specific household‚Äôs shopping.</li>
    </ul>
  </section>

  <section>
    <h2>How (Starter Pack)</h2>
    <ul>
      <li>Pick a mechanism (Laplace/Gaussian) and set a sensible <code>Œµ</code> (lower = stronger privacy).</li>
      <li>Budget privacy across queries; stop when the budget is spent.</li>
      <li>Release only aggregates; avoid raw microdata exports.</li>
      <li>Document your DP configuration and residual risks in a tech note.</li>
    </ul>
  </section>

  <section class="refs">
    <h2>References</h2>
    <ul>
      <li>Dwork &amp; Roth (2014), <em>Algorithmic Foundations of Differential Privacy</em>: <a href="https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf" target="_blank" rel="noopener">privacybook.pdf</a></li>
      <li>Apple Differential Privacy (overview): <a href="https://www.apple.com/privacy/docs/Differential_Privacy_Overview.pdf" target="_blank" rel="noopener">apple.com/privacy/docs/...</a></li>
    </ul>
  </section>
</main>
</body>
</html>
